<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=author content><meta name=description content="ARTS - Tip 补12.3 MySQL备份数据过滤与自动化 导数据 在工作中要同步生产数据到测试服务器的需求，以方便测试，于是经常要复制表.
最开始我是这么做的：
// 首先备份表 mysqldump -uusername -p dbname tablename &amp;gt; tablename.sql // 把表复制到其他服务器 scp tablename.sql user@ip:~/ // 登录user机器，导入数据 mysql -uusername -p dbname &amp;lt; tablename.sql 由于测试机测试和本机测试还是不一样，有时使用 sz tablename.sql 到本地，再测试，这种情况下如果网络不好，而且数据文件非常大，要很慢才能传送完毕，于是就想到，有些数据按天产生，只需要最近几天的数据，对于之前的没必要传送。于是查文档找到了方案.
备份数据过滤 &amp;ndash;tables Override the &amp;ndash;databases or -B option. mysqldump regards all name arguments following the option as table names.
&amp;ndash;where=&amp;lsquo;where_condition&amp;rsquo;, -w &amp;lsquo;where_condition&amp;rsquo;
Dump only rows selected by the given WHERE condition. Quotes around the condition are mandatory if it contains spaces or other characters that are special to your command interpreter."><meta name=keywords content=",arts"><meta name=robots content="noodp"><meta name=theme-color content><link rel=canonical href=/posts/arts/week1022_tip/><title>Week1022_tip :: Hello Friend — A coder's Homepage</title><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.5.0/css/flag-icon.min.css integrity="sha512-Cv93isQdFwaKBV+Z4X8kaVBYWHST58Xb/jVOcV9aRsGSArZsgAnFIhMpDoMDcFNoUtday1hdjn0nGp3+KZyyFw==" crossorigin=anonymous referrerpolicy=no-referrer><link rel=stylesheet href=/main.2a064c455b0ecbd6b1481b3bf9df2441e95838691022f40a5338c2cb1244f075.css integrity="sha256-KgZMRVsOy9axSBs7+d8kQelYOGkQIvQKUzjCyxJE8HU="><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color><link rel="shortcut icon" href=/favicon.ico><meta name=msapplication-TileColor content><meta itemprop=name content="Week1022_tip"><meta itemprop=description content="ARTS - Tip 补12.3 MySQL备份数据过滤与自动化 导数据 在工作中要同步生产数据到测试服务器的需求，以方便测试，于是经常要复制表.
最开始我是这么做的：
// 首先备份表 mysqldump -uusername -p dbname tablename > tablename.sql // 把表复制到其他服务器 scp tablename.sql user@ip:~/ // 登录user机器，导入数据 mysql -uusername -p dbname < tablename.sql 由于测试机测试和本机测试还是不一样，有时使用 sz tablename.sql 到本地，再测试，这种情况下如果网络不好，而且数据文件非常大，要很慢才能传送完毕，于是就想到，有些数据按天产生，只需要最近几天的数据，对于之前的没必要传送。于是查文档找到了方案.
备份数据过滤 &ndash;tables Override the &ndash;databases or -B option. mysqldump regards all name arguments following the option as table names.
&ndash;where=&lsquo;where_condition&rsquo;, -w &lsquo;where_condition&rsquo;
Dump only rows selected by the given WHERE condition. Quotes around the condition are mandatory if it contains spaces or other characters that are special to your command interpreter."><meta itemprop=datePublished content="2023-03-31T15:45:40+00:00"><meta itemprop=dateModified content="2023-03-31T15:45:40+00:00"><meta itemprop=wordCount content="258"><meta itemprop=keywords content="arts,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Week1022_tip"><meta name=twitter:description content="ARTS - Tip 补12.3 MySQL备份数据过滤与自动化 导数据 在工作中要同步生产数据到测试服务器的需求，以方便测试，于是经常要复制表.
最开始我是这么做的：
// 首先备份表 mysqldump -uusername -p dbname tablename > tablename.sql // 把表复制到其他服务器 scp tablename.sql user@ip:~/ // 登录user机器，导入数据 mysql -uusername -p dbname < tablename.sql 由于测试机测试和本机测试还是不一样，有时使用 sz tablename.sql 到本地，再测试，这种情况下如果网络不好，而且数据文件非常大，要很慢才能传送完毕，于是就想到，有些数据按天产生，只需要最近几天的数据，对于之前的没必要传送。于是查文档找到了方案.
备份数据过滤 &ndash;tables Override the &ndash;databases or -B option. mysqldump regards all name arguments following the option as table names.
&ndash;where=&lsquo;where_condition&rsquo;, -w &lsquo;where_condition&rsquo;
Dump only rows selected by the given WHERE condition. Quotes around the condition are mandatory if it contains spaces or other characters that are special to your command interpreter."><meta property="og:title" content="Week1022_tip"><meta property="og:description" content="ARTS - Tip 补12.3 MySQL备份数据过滤与自动化 导数据 在工作中要同步生产数据到测试服务器的需求，以方便测试，于是经常要复制表.
最开始我是这么做的：
// 首先备份表 mysqldump -uusername -p dbname tablename > tablename.sql // 把表复制到其他服务器 scp tablename.sql user@ip:~/ // 登录user机器，导入数据 mysql -uusername -p dbname < tablename.sql 由于测试机测试和本机测试还是不一样，有时使用 sz tablename.sql 到本地，再测试，这种情况下如果网络不好，而且数据文件非常大，要很慢才能传送完毕，于是就想到，有些数据按天产生，只需要最近几天的数据，对于之前的没必要传送。于是查文档找到了方案.
备份数据过滤 &ndash;tables Override the &ndash;databases or -B option. mysqldump regards all name arguments following the option as table names.
&ndash;where=&lsquo;where_condition&rsquo;, -w &lsquo;where_condition&rsquo;
Dump only rows selected by the given WHERE condition. Quotes around the condition are mandatory if it contains spaces or other characters that are special to your command interpreter."><meta property="og:type" content="article"><meta property="og:url" content="/posts/arts/week1022_tip/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-03-31T15:45:40+00:00"><meta property="article:modified_time" content="2023-03-31T15:45:40+00:00"><meta property="og:site_name" content="Hello Friend "><meta property="article:published_time" content="2023-03-31 15:45:40 +0000 UTC"></head><body><div class=container><header class=header><span class=header__inner><a href=/ style=text-decoration:none><div class=logo><span class=logo__mark>></span>
<span class=logo__text>hello world...</span>
<span class=logo__cursor></span></div></a><span class=header__right><nav class=menu><ul class=menu__inner><li><a href=/about>About</a></li><li><a href=/posts>Blog</a></li><li><a href=/categorys>Category</a></li><li><a href=/series>Series</a></li></ul></nav><span class=menu-trigger><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg></span></span></span></header><div class=content><main class=post><div class=post-info><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 16 14"/></svg>2 minutes</p></div><article><h1 class=post-title><a href=/posts/arts/week1022_tip/>Week1022_tip</a></h1><div class=post-content><h2 id=arts---tip-补123>ARTS - Tip 补12.3</h2><h3 id=mysql备份数据过滤与自动化>MySQL备份数据过滤与自动化</h3><h4 id=导数据>导数据</h4><p>在工作中要同步生产数据到测试服务器的需求，以方便测试，于是经常要复制表.</p><p>最开始我是这么做的：</p><pre tabindex=0><code>// 首先备份表
mysqldump -uusername  -p dbname tablename &gt; tablename.sql
// 把表复制到其他服务器
scp tablename.sql user@ip:~/

// 登录user机器，导入数据
mysql -uusername -p dbname &lt; tablename.sql
</code></pre><p>由于测试机测试和本机测试还是不一样，有时使用 sz tablename.sql 到本地，再测试，这种情况下如果网络不好，而且数据文件非常大，要很慢才能传送完毕，于是就想到，有些数据按天产生，只需要最近几天的数据，对于之前的没必要传送。于是查文档找到了方案.</p><h4 id=备份数据过滤>备份数据过滤</h4><blockquote><p>&ndash;tables
Override the &ndash;databases or -B option. mysqldump regards all name arguments following the option as table names.</p><p>&ndash;where=&lsquo;where_condition&rsquo;, -w &lsquo;where_condition&rsquo;</p></blockquote><blockquote><p>Dump only rows selected by the given WHERE condition. Quotes around the condition are mandatory if it contains spaces or other characters that are special to your command interpreter.</p></blockquote><blockquote><p>Examples:</p></blockquote><blockquote><p>&ndash;where=&ldquo;user=&lsquo;jimf&rsquo;&rdquo;</p><p>-w"userid>1"</p></blockquote><blockquote><p>-w"userid&lt;1"</p></blockquote><p>可以使用 &ndash;tables 和 &ndash;where 来过滤，
如我有t_user表</p><pre tabindex=0><code>mysql&gt; select * from t_user;
+----+------+------+-------------+
| id | name | age  | telephone   |
+----+------+------+-------------+
|  1 | jack |   20 | 18877771111 |
|  2 | rose |   33 | 18977771111 |
|  3 | tom  |   21 | 13877761111 |
|  4 | bob  |   24 | 13356771111 |
+----+------+------+-------------+
</code></pre><p>要备份id >2的数据，使用</p><pre tabindex=0><code>mysqldump -uroot -p dbname --tables t_user --where=&#34;id&gt;2&#34; &gt; t_user.sql
</code></pre><p>打开文件t_user.sql， 部分如下</p><pre tabindex=0><code>--
 -- WHERE:  id&gt;2

 LOCK TABLES `t_user` WRITE;
 /*!40000 ALTER TABLE `t_user` DISABLE KEYS */;
 INSERT INTO `t_user` VALUES (3,&#39;tom&#39;,21,&#39;13877761111&#39;),(4,&#39;bob&#39;,24,&#39;13356771111&#39;);
 /*!40000 ALTER TABLE `t_user` ENABLE KEYS */;
 UNLOCK TABLES;
</code></pre><p>可见，已经生效了</p><h4 id=脚本化>脚本化</h4><p>我想自动化同步表数据，于是就写了个shell脚本来实现，
对于同步服务器脚本如下：</p><pre tabindex=0><code>#!/bin/bash
 echo &#34;####start sync data to test####&#34;

 for i in &#34;$@&#34;; do
     echo $i
     mysqldump -uusername -ppassword db $i &gt; &#34;$i.sql&#34;
     scp &#34;$i.sql&#34; user@test_ip:~/script/ &amp;
 done

 wait
 rm ./*.sql
 echo &#34;####end sync data####&#34;
</code></pre><p>该脚本参数是要同步的表，对于测试服务器脚本如下：</p><pre tabindex=0><code>#!/bin/bash
 echo &#34;####start import sql####&#34;

 for i in $(ls *.sql); do
     echo $i
     mysql -uusername -ppassword db &lt;  &#34;$i&#34; &amp;
 done

wait
mv *.sql ../tmp

 echo &#34;### end import###&#34;
</code></pre><p>以上就做到了简单了数据同步，还没实现在服务器A调用B的脚本的功能，以后在加。</p></div></article><hr><div class=post-info><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z"/><line x1="7" y1="7" x2="7" y2="7"/></svg><span class=tag><a href=/tags/arts/>arts</a></span></p><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><polyline points="14 2 14 8 20 8"/><line x1="16" y1="13" x2="8" y2="13"/><line x1="16" y1="17" x2="8" y2="17"/><polyline points="10 9 9 9 8 9"/></svg>258 Words</p><p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>2023-03-31 15:45</p></div><div class=pagination><div class=pagination__title><span class=pagination__title-h>Read other posts</span><hr></div><div class=pagination__buttons><span class="button previous"><a href=/posts/arts/week1022_share/><span class=button__icon>←</span>
<span class=button__text>Week1022_share</span></a></span>
<span class="button next"><a href=/posts/arts/week1023_algorithm/><span class=button__text>Week1023_algorithm</span>
<span class=button__icon>→</span></a></span></div></div></main></div><footer class=footer></footer></div><script type=text/javascript src=/bundle.min.c90b8161416b87c69a8e02683b54ddd6edb90aea699648bf655e6cbc45b419b8e465d196e715772463dba35a6faf5decb2eb247480d38680484d54645b434570.js integrity="sha512-yQuBYUFrh8aajgJoO1Td1u25Cupplki/ZV5svEW0GbjkZdGW5xV3JGPbo1pvr13ssuskdIDThoBITVRkW0NFcA=="></script></body></html>